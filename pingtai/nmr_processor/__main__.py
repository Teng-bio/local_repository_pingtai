#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
NMR-GCFåˆ†æè½¯ä»¶åŒ…ä¸»å…¥å£ã€‚
æä¾›å‘½ä»¤è¡Œç•Œé¢å’Œä¸»è¦å·¥ä½œæµç¨‹ã€‚
âœ… å·²ä¿®å¤æ‰€æœ‰å…¼å®¹æ€§é—®é¢˜
"""

import os
import sys
import logging
import argparse
from pathlib import Path
from datetime import datetime

# å¯¼å…¥é…ç½®æ¨¡å—ï¼ˆå·²æ•´åˆæ‰€æœ‰é…ç½®ç®¡ç†åŠŸèƒ½ï¼‰
from nmr_processor.config import Config
from nmr_processor.processor import run_nmr_processing
from nmr_processor.converter import find_and_convert_tab_files, organize_nmr_samples
from nmr_processor.analysis.base import analyze_nmr_data
from nmr_processor.analysis.gcf_peak_matcher import match_gcf_peaks
from nmr_processor.utils.memory_protector import (
    MemoryProtector, 
    with_memory_protection,
    memory_limit,
    MemoryLeakDetector,
    emergency_cleanup
)

def setup_logging(log_dir=None):
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    if log_dir is None:
        log_dir = os.path.join(Config.get_output_path(), "logs")
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(log_dir, exist_ok=True)
    
    log_file = os.path.join(log_dir, f"nmr_process_{timestamp}.log")
    
    # é…ç½®æ—¥å¿—è®°å½•
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return log_file

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="NMR-GCFåˆ†æè½¯ä»¶åŒ…")
    
    # ä¸»è¦æ¨¡å¼é€‰æ‹©
    parser.add_argument("--mode", type=str, 
                      choices=["all", "process", "convert", "analyze", "match", "config"],
                      default="all", 
                      help="æ‰§è¡Œæ¨¡å¼: all=å®Œæ•´æµç¨‹, process=ä»…NMRå¤„ç†, convert=ä»…è½¬æ¢, "
                           "analyze=ä»…åˆ†æ, match=ä»…GCF-å³°åŒ¹é…, config=é…ç½®æ›´æ–°")
    
    # é€šç”¨å‚æ•°
    parser.add_argument("--base_dir", type=str, help="åŸºç¡€æ•°æ®ç›®å½•", default=None)
    parser.add_argument("--output_dir", type=str, help="è¾“å‡ºç›®å½•", default=None)
    parser.add_argument("--log_dir", type=str, help="æ—¥å¿—ç›®å½•")
    
    # NMRå¤„ç†å‚æ•°
    parser.add_argument("--script", type=str, help="tcshè„šæœ¬çš„è·¯å¾„", default=None)
    parser.add_argument("--data_dir", type=str, help="æ•°æ®ç›®å½•", default=None)
    parser.add_argument("--process_flag", type=str, help="å¤„ç†æ ‡å¿—", default="2")
    parser.add_argument("--no-convert", action="store_true", 
                      help="ç¦ç”¨tabæ–‡ä»¶è‡ªåŠ¨è½¬æ¢ä¸ºCSV")
    parser.add_argument("--convert-only", action="store_true", 
                      help="ä»…è½¬æ¢tabæ–‡ä»¶ä¸ºCSVï¼Œä¸æ‰§è¡ŒNMRå¤„ç†")
    parser.add_argument("--organize", action="store_true", 
                      help="ç»„ç»‡NMRæ•°æ®åˆ°æ ‡å‡†åŒ–çš„æ–‡ä»¶å¤¹ç»“æ„")
    parser.add_argument("--in-place", action="store_true", 
                      help="åœ¨åŸä½ç½®ä¿å­˜CSVæ–‡ä»¶ï¼ˆé»˜è®¤ï¼šFalseï¼‰")
    
    # GCF-å³°åŒ¹é…å‚æ•°
    parser.add_argument("--gcf_matrix", type=str, help="GCFçŸ©é˜µæ–‡ä»¶è·¯å¾„", default=None)
    parser.add_argument("--workers", type=int, help="å·¥ä½œè¿›ç¨‹æ•°", default=None)
    parser.add_argument("--batch_size", type=int, help="æ‰¹å¤„ç†å¤§å°", default=None)

    # å³°åˆ†ç±»å™¨å‚æ•°
    parser.add_argument("--use-classifier", action="store_true", 
                      help="å¯ç”¨å³°åˆ†ç±»å™¨è¿‡æ»¤ä½ç½®ä¿¡åº¦å³°")
    parser.add_argument("--classifier-threshold", type=float, default=0.5, 
                      help="å³°åˆ†ç±»å™¨ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.5ï¼‰")
    parser.add_argument("--classifier-model", type=str, 
                      help="å³°åˆ†ç±»å™¨æ¨¡å‹æ–‡ä»¶è·¯å¾„")
    
    # èšç±»å’Œæ‰“åˆ†å‚æ•°
    parser.add_argument("--clustering-tolerance", type=float, 
                      help="DBSCANèšç±»å®¹å·®ï¼ˆppmï¼‰ï¼Œé»˜è®¤0.002")
    parser.add_argument("--perfect-match-score", type=int,
                      help="å®Œç¾åŒ¹é…å¾—åˆ†ï¼Œé»˜è®¤10")
    parser.add_argument("--orphan-peak-score", type=int,
                      help="å­¤ç«‹å³°æ‰£åˆ†ï¼Œé»˜è®¤-10")
    
    return parser.parse_args()

def update_config_from_args(args):
    """ä»å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®"""
    # æ›´æ–°åŸºç¡€è·¯å¾„
    if args.base_dir:
        Config.BASE_PATH = os.path.abspath(args.base_dir)
        logging.info(f"å·²è®¾ç½®åŸºç¡€è·¯å¾„: {Config.BASE_PATH}")
    
    # æ›´æ–°è¾“å‡ºè·¯å¾„
    if args.output_dir:
        output_dir = os.path.abspath(args.output_dir)
        Config._custom_output_path = output_dir
        original_get_output_path = Config.get_output_path
        Config.get_output_path = classmethod(
            lambda cls: Config._custom_output_path if hasattr(Config, '_custom_output_path') 
            else original_get_output_path()
        )
        logging.info(f"å·²è®¾ç½®è¾“å‡ºè·¯å¾„: {output_dir}")
    
    if args.data_dir:
        data_dir = os.path.abspath(args.data_dir)
        Config._custom_nmr_data_path = data_dir
        original_get_nmr_data_path = Config.get_nmr_data_path
        Config.get_nmr_data_path = classmethod(
            lambda cls: Config._custom_nmr_data_path if hasattr(Config, '_custom_nmr_data_path') 
            else original_get_nmr_data_path()
        )
        logging.info(f"å·²è®¾ç½®NMRæ•°æ®è·¯å¾„: {data_dir}")
    
    if args.script:
        Config.SCRIPT_PATH = os.path.abspath(args.script)
        logging.info(f"å·²è®¾ç½®è„šæœ¬è·¯å¾„: {Config.SCRIPT_PATH}")
    
    if args.gcf_matrix:
        gcf_matrix = os.path.abspath(args.gcf_matrix)
        Config._custom_gcf_matrix_path = gcf_matrix
        original_get_gcf_matrix_path = Config.get_gcf_matrix_path
        Config.get_gcf_matrix_path = classmethod(
            lambda cls: Config._custom_gcf_matrix_path if hasattr(Config, '_custom_gcf_matrix_path') 
            else original_get_gcf_matrix_path()
        )
        logging.info(f"å·²è®¾ç½®GCFçŸ©é˜µè·¯å¾„: {gcf_matrix}")
    
    # æ›´æ–°å¤„ç†å‚æ•°
    if args.workers:
        Config.NUM_WORKERS = args.workers
        logging.info(f"å·²è®¾ç½®å·¥ä½œè¿›ç¨‹æ•°: {Config.NUM_WORKERS}")
    
    if args.batch_size:
        Config.BATCH_SIZE = args.batch_size
        logging.info(f"å·²è®¾ç½®æ‰¹å¤„ç†å¤§å°: {Config.BATCH_SIZE}")
    
    # æ›´æ–°å³°åˆ†ç±»å™¨é…ç½®
    if args.use_classifier:
        Config.USE_PEAK_CLASSIFIER = True
        logging.info("å·²å¯ç”¨å³°åˆ†ç±»å™¨")

    if args.classifier_threshold:
        Config.PEAK_CONFIDENCE_THRESHOLD = args.classifier_threshold
        logging.info(f"å³°åˆ†ç±»å™¨ç½®ä¿¡åº¦é˜ˆå€¼: {Config.PEAK_CONFIDENCE_THRESHOLD}")

    if args.classifier_model:
        Config.PEAK_CLASSIFIER_MODEL_PATH = os.path.abspath(args.classifier_model)
        logging.info(f"å³°åˆ†ç±»å™¨æ¨¡å‹è·¯å¾„: {Config.PEAK_CLASSIFIER_MODEL_PATH}")
    
    # æ›´æ–°èšç±»å’Œæ‰“åˆ†é…ç½®
    if args.clustering_tolerance:
        Config.PEAK_CLUSTERING['tolerance'] = args.clustering_tolerance
        logging.info(f"DBSCANèšç±»å®¹å·®: {Config.PEAK_CLUSTERING['tolerance']}")
    
    if args.perfect_match_score:
        Config.SCORING_CONFIG['perfect_match'] = args.perfect_match_score
        logging.info(f"å®Œç¾åŒ¹é…å¾—åˆ†: {Config.SCORING_CONFIG['perfect_match']}")
    
    if args.orphan_peak_score:
        Config.SCORING_CONFIG['orphan_peak'] = args.orphan_peak_score
        logging.info(f"å­¤ç«‹å³°æ‰£åˆ†: {Config.SCORING_CONFIG['orphan_peak']}")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    Config.create_directories()

def main():
    """ä¸»å‡½æ•° - è½¯ä»¶åŒ…å…¥å£ç‚¹"""
    # åˆå§‹åŒ–å…¨å±€å†…å­˜ä¿æŠ¤å™¨
    global_protector = MemoryProtector(max_memory_percent=90)
    
    # æ£€æŸ¥åˆå§‹å†…å­˜çŠ¶æ€
    status, _, info = global_protector.check_memory(force=True)
    if status != 'safe':
        logging.warning(
            f"âš ï¸ å¯åŠ¨æ—¶å†…å­˜å·²è¾ƒé«˜: {info['system_used_percent']:.1f}%"
        )
    
    # ä½¿ç”¨æ•´åˆåçš„é…ç½®æ–¹æ³•æ£€æŸ¥é¦–æ¬¡è¿è¡Œ
    first_run = Config.first_run_check()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    # å¦‚æœæ˜¯é…ç½®æ¨¡å¼ï¼Œç›´æ¥è¿›å…¥é…ç½®æ›´æ–°
    if args.mode == "config":
        Config.update_config_entry()
        return 0
    
    # ä½¿ç”¨æ•´åˆåçš„é…ç½®æ–¹æ³•åŠ è½½ç”¨æˆ·é…ç½®
    user_config = Config.get_user_config()
    
    # ä»ç”¨æˆ·é…ç½®æ›´æ–°è®¾ç½®
    for key, value in user_config.items():
        if hasattr(Config, key.upper()):
            setattr(Config, key.upper(), value)
        elif key == 'data_dir' and value:
            Config.BASE_PATH = os.path.dirname(value)
    
    # ä»å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®
    update_config_from_args(args)
    
    # åœ¨ç»§ç»­ä¹‹å‰åˆ›å»ºå¿…è¦çš„ç›®å½•
    Config.create_directories()
    
    # è®¾ç½®æ—¥å¿—
    log_dir = args.log_dir if args.log_dir else os.path.join(Config.get_output_path(), "logs")
    log_file = setup_logging(log_dir)
    
    print("=" * 60)
    print("        NMR-GCFåˆ†æè½¯ä»¶åŒ… (å‡çº§ç‰ˆ)")
    print("=" * 60)
    print(f"æ¨¡å¼: {args.mode}")
    print(f"åŸºç¡€ç›®å½•: {Config.BASE_PATH}")
    print(f"è¾“å‡ºç›®å½•: {Config.get_output_path()}")
    print(f"NMRæ•°æ®ç›®å½•: {Config.get_nmr_data_path()}")
    print(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    print("\næ–°åŠŸèƒ½:")
    print(f"  - DBSCANå³°èšç±»: tolerance={Config.PEAK_CLUSTERING['tolerance']}")
    print(f"  - çµæ´»æ‰“åˆ†ç³»ç»Ÿ: å®Œç¾åŒ¹é…={Config.SCORING_CONFIG['perfect_match']}, "
          f"å­¤ç«‹å³°={Config.SCORING_CONFIG['orphan_peak']}")
    print(f"  - å³°åˆ†ç±»å™¨: {'å¯ç”¨' if Config.USE_PEAK_CLASSIFIER else 'ç¦ç”¨'}")
    if Config.USE_PEAK_CLASSIFIER:
        print(f"    ç½®ä¿¡åº¦é˜ˆå€¼: {Config.PEAK_CONFIDENCE_THRESHOLD}")
    print("=" * 60)
    
    try:
        # ä½¿ç”¨å†…å­˜é™åˆ¶ä¸Šä¸‹æ–‡
        with memory_limit(max_percent=90) as protector:
            # æ ¹æ®é€‰æ‹©çš„æ¨¡å¼æ‰§è¡Œç›¸åº”çš„åŠŸèƒ½
            if args.mode in ["all", "process"]:
                print("\n[1] æ‰§è¡ŒNMRæ•°æ®å¤„ç†...")
                # æ£€æŸ¥å†…å­˜
                status, _, info = protector.check_memory(force=True)
                if status == 'warning':
                    logging.warning("å†…å­˜æ¥è¿‘é™åˆ¶ï¼Œå¯èƒ½éœ€è¦é™çº§å¤„ç†")
                
                return_code, log_file, csv_files = run_nmr_processing(
                    script_path=Config.SCRIPT_PATH,
                    data_dir=Config.get_nmr_data_path(),
                    process_flag=args.process_flag,
                    convert_tabs=not args.no_convert
                )
                
                if return_code != 0:
                    print(f"NMRå¤„ç†å¤±è´¥ï¼Œè¿”å›ç : {return_code}")
                    if args.mode == "process":
                        return return_code
                else:
                    print(f"NMRå¤„ç†æˆåŠŸå®Œæˆï¼Œç”Ÿæˆ {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
                protector.force_gc()
                
            
            if args.mode in ["all", "convert"] or args.convert_only:
                print("\n[2] æ‰§è¡Œtabæ–‡ä»¶è½¬æ¢...")
                if args.organize:
                    print("ç»„ç»‡å¹¶è½¬æ¢NMRæ•°æ®...")
                    strain_samples = organize_nmr_samples(
                        Config.get_nmr_data_path(), 
                        Config.get_output_path()
                    )
                    print(f"æ•°æ®ç»„ç»‡å®Œæˆï¼Œå…±å¤„ç†äº† {len(strain_samples)} ä¸ªèŒæ ª")
                else:
                    print("è½¬æ¢tabæ–‡ä»¶ä¸ºCSV...")
                    csv_files = find_and_convert_tab_files(
                        Config.get_nmr_data_path(), 
                        Config.get_output_path(),
                        in_place=args.in_place
                    )
                    print(f"è½¬æ¢å®Œæˆï¼Œå…±ç”Ÿæˆ {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
                protector.force_gc()
            
            if args.mode in ["all", "analyze"]:
                print("\n[3] æ‰§è¡ŒNMRæ•°æ®åˆ†æ...")
                output_dir = analyze_nmr_data(
                    gcf_matrix_path=Config.get_gcf_matrix_path(),
                    nmr_data_path=Config.get_nmr_data_path(),
                    output_path=Config.get_output_path()
                )
                protector.force_gc()
                print(f"NMRæ•°æ®åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {output_dir}")
            
            if args.mode in ["all", "match"]:
                print("\n[4] æ‰§è¡ŒGCF-å³°åŒ¹é…åˆ†æ (DBSCANèšç±»æ¨¡å¼)...")
                # åˆ†æå‰ä¼°ç®—å†…å­˜
                estimated_gb, is_safe = protector.estimate_memory_needed(
                    data_size=1024**3,  # å‡è®¾1GBæ•°æ®
                    factor=5.0
                )
                if not is_safe:
                    logging.warning(
                        f"âš ï¸ å†…å­˜å¯èƒ½ä¸è¶³ï¼ˆéœ€è¦~{estimated_gb:.1f}GBï¼‰ï¼Œ"
                        "å»ºè®®åˆ†æ‰¹å¤„ç†"
                    )
                    
                    response = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ")
                    if response.lower() != 'y':
                        return 1
                
                print(f"ä½¿ç”¨èšç±»å®¹å·®: {Config.PEAK_CLUSTERING['tolerance']} ppm")
                print(f"æ‰“åˆ†è§„åˆ™: å®Œç¾åŒ¹é…={Config.SCORING_CONFIG['perfect_match']}, "
                      f"ç¼ºå¤±å³°={Config.SCORING_CONFIG['missing_peak']}, "
                      f"å­¤ç«‹å³°={Config.SCORING_CONFIG['orphan_peak']}")
                
                output_dir = match_gcf_peaks(
                    gcf_matrix_path=Config.get_gcf_matrix_path(),
                    nmr_data_path=Config.get_nmr_data_path(),
                    output_path=Config.get_output_path()
                )
                protector.force_gc()
                print(f"GCF-å³°åŒ¹é…åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {output_dir}")
                print("\nè¾“å‡ºå†…å®¹:")
                print("  - æŒ‰èŒæ ªçš„æ–‡ä»¶å¤¹ï¼ˆæ¯ä¸ªèŒæ ªä¸€ä¸ªå­ç›®å½•ï¼‰")
                print("  - {strain}_{fraction}_rank.csvï¼ˆæŒ‰æ€»åˆ†æ’åºçš„ç°‡ï¼‰")
                print("  - {strain}_summary.csvï¼ˆèŒæ ªæ±‡æ€»æŠ¥å‘Šï¼‰")
                print("  - SQLiteæ•°æ®åº“ï¼ˆgcf_peak_analysis.dbï¼‰")
            
            print("\næ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
            # è¾“å‡ºæœ€ç»ˆå†…å­˜æŠ¥å‘Š
            final_info = global_protector.get_memory_info()
            print("\n" + "=" * 80)
            print("ğŸ“Š æœ€ç»ˆå†…å­˜æŠ¥å‘Š")
            print("=" * 80)
            print(f"å³°å€¼å†…å­˜: {final_info['peak_memory_gb']:.2f} GB")
            print(f"æœ€ç»ˆä½¿ç”¨: {final_info['system_used_percent']:.1f}%")
            print("=" * 80)
            return 0
            
    except MemoryError as e:
        print(f"\nğŸ’¥ å†…å­˜ä¸è¶³: {e}")
        print("\nå»ºè®®æªæ–½ï¼š")
        print("  1. å…³é—­å…¶ä»–ç¨‹åºé‡Šæ”¾å†…å­˜")
        print("  2. å¢åŠ ç³»ç»Ÿå†…å­˜ï¼ˆç‰©ç†å†…å­˜æˆ–äº¤æ¢ç©ºé—´ï¼‰")
        print("  3. å‡å°å¤„ç†æ‰¹æ¬¡å¤§å°")
        print("  4. ä½¿ç”¨ --batch_size å’Œ --workers å‚æ•°è°ƒæ•´")
        return 1
    
    except KeyboardInterrupt:
        print("\næ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        # æ¸…ç†
        emergency_cleanup()
        return 1
    
    except Exception as e:
        logging.error(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        logging.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        return 1

if __name__ == "__main__":
    sys.exit(main())
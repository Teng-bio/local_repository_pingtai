#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
NMR tab file converter module.
Converts tab-delimited peak list files to CSV format for further processing.
"""

import os
import re
import csv
import pandas as pd
import logging
from pathlib import Path
import shutil
from .config import Config

def extract_simple_name(name):
    """
    ä»Žå¤æ‚çš„åç§°ä¸­æå–ç®€åŒ–ç‰ˆæœ¬
    ä¾‹å¦‚ï¼šä»Ž"Du-SDU37-Fr3"æå–"fr3"ï¼Œæˆ–ä»Ž"Du-SDU37-F2"æå–"fr2"
    
    Parameters:
        name (str): åŽŸå§‹åç§°
        
    Returns:
        str: ç®€åŒ–åŽçš„åç§°
    """
    # æŸ¥æ‰¾Fræˆ–FåŽé¢çš„æ•°å­—
    import re
    match = re.search(r'[Ff]r?(\d+)', name)
    if match:
        number = match.group(1)
        return f"fr{number}"
    else:
        return name

def tab_to_csv(tab_file_path, output_dir=None, strain_id=None, sample_id=None, use_simple_names=True):
    """
    Convert NMR tab file to CSV format
    
    Parameters:
        tab_file_path (str): Path to tab file
        output_dir (str): Directory to save CSV file (defaults to same directory as tab file)
        strain_id (str): Strain identifier (optional)
        sample_id (str): Sample identifier (optional)
        use_simple_names (bool): Whether to simplify strain and sample names
    
    Returns:
        str: Path to the created CSV file
    """
    tab_file_path = Path(tab_file_path)
    
    # Create output directory if not specified
    if output_dir is None:
        output_dir = tab_file_path.parent
    else:
        output_dir = Path(output_dir)
    
    # Create directory if it doesn't exist
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä»Žæ–‡ä»¶è·¯å¾„ä¸­è§£æžèŒæ ªå’Œæ ·æœ¬ä¿¡æ¯
    if strain_id is None or sample_id is None:
        # å°è¯•ä»Žè·¯å¾„ä¸­æå–èŒæ ªå’Œæ ·æœ¬ä¿¡æ¯
        # é¢„æœŸçš„è·¯å¾„: /ä¸»æ–‡ä»¶å¤¹/èŒæ ªåç§°/æ ·æœ¬å/10/nmrpipe/spectrum.tab
        parts = list(tab_file_path.parts)
        
        # æŸ¥æ‰¾"nmrpipe"æ–‡ä»¶å¤¹ä½ç½®
        nmrpipe_idx = -1
        for i, part in enumerate(parts):
            if part == "nmrpipe":
                nmrpipe_idx = i
                break
        
        if nmrpipe_idx > 2:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„è·¯å¾„æ·±åº¦
            # nmrpipeçš„ä¸Šä¸¤çº§åº”è¯¥æ˜¯"10"æ–‡ä»¶å¤¹å’Œæ ·æœ¬å
            if parts[nmrpipe_idx-1] == "10" and nmrpipe_idx >= 3:
                sample_dir = parts[nmrpipe_idx-2]
                strain_dir = parts[nmrpipe_idx-3]
                
                if strain_id is None:
                    strain_id = strain_dir
                
                if sample_id is None:
                    sample_id = sample_dir
        
        # å¦‚æžœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
        if strain_id is None:
            # å°è¯•æ‰¾åˆ°çˆ¶ç›®å½•ä¸­çš„èŒæ ªå
            parent_dir = tab_file_path.parent
            while parent_dir.name and parent_dir.name != "/":
                if "SDU" in parent_dir.name or "Fr" in parent_dir.name:
                    strain_id = parent_dir.name
                    break
                parent_dir = parent_dir.parent
            
            if strain_id is None:
                strain_id = "unknown_strain"
        
        if sample_id is None:
            # ä½¿ç”¨ç›®å½•åä½œä¸ºæ ·æœ¬ID
            parent_dir = tab_file_path.parent
            if parent_dir.name == "nmrpipe":
                parent_dir = parent_dir.parent
                if parent_dir.name == "10":
                    parent_dir = parent_dir.parent
            
            sample_id = parent_dir.name
    
    # ç®€åŒ–åç§°ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
    original_strain_id = strain_id
    original_sample_id = sample_id
    
    if use_simple_names:
        strain_id = extract_simple_name(strain_id)
        sample_id = extract_simple_name(sample_id)
    
    # åˆ›å»ºCSVæ–‡ä»¶å
    csv_filename = f"{strain_id}_{sample_id}_peaks.csv"
    csv_file_path = output_dir / csv_filename
    
    # è¯»å–å¹¶è§£æžtabæ–‡ä»¶
    try:
        with open(tab_file_path, 'r') as tab_file:
            lines = tab_file.readlines()
    except UnicodeDecodeError:
        # å¦‚æžœé»˜è®¤ç¼–ç å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä¸åŒçš„ç¼–ç 
        try:
            with open(tab_file_path, 'r', encoding='latin1') as tab_file:
                lines = tab_file.readlines()
        except:
            logging.error(f"æ— æ³•è¯»å–æ–‡ä»¶: {tab_file_path}")
            raise
    
    # æå–å¤´éƒ¨ä¿¡æ¯
    header_line = None
    format_line = None
    data_lines = []
    
    for line in lines:
        line = line.strip()
        if line.startswith("VARS"):
            header_line = line
        elif line.startswith("FORMAT"):
            format_line = line
        elif line and not line.startswith("#"):
            data_lines.append(line)
    
    if not header_line:
        logging.warning(f"æ–‡ä»¶æ ¼å¼ä¸æ ‡å‡†: {tab_file_path}ï¼Œæ— VARSå¤´éƒ¨")
        # å°è¯•ä»Žæ–‡ä»¶å†…å®¹çŒœæµ‹æ ¼å¼
        if len(data_lines) > 0 and len(data_lines[0].split()) >= 5:
            # å‡è®¾è¿™æ˜¯spectrum.tabæ–‡ä»¶çš„æ ‡å‡†æ ¼å¼ï¼Œåˆ—åä¸ºINDEX, X_AXIS, X_PPM, XW, HEIGHT, CONFIDENCE
            header_line = "VARS INDEX X_AXIS X_PPM XW HEIGHT CONFIDENCE"
            logging.info(f"ä½¿ç”¨é»˜è®¤åˆ—å: {header_line}")
        else:
            raise ValueError(f"æ— æ•ˆçš„tabæ–‡ä»¶æ ¼å¼: {tab_file_path}ã€‚æ— æ³•æ‰¾åˆ°VARSå¤´éƒ¨ä¿¡æ¯ã€‚")
    
    # æå–åˆ—å
    column_names = header_line.strip().split()[1:]  # è·³è¿‡"VARS"
    logging.debug(f"åˆ—å: {column_names}")
    
    # è§£æžæ•°æ®
    data = []
    for line in data_lines:
        values = line.strip().split()
        # ç¡®ä¿æ•°æ®ä¸Žåˆ—æ•°åŒ¹é…
        if len(values) >= len(column_names):
            # å¦‚æžœæ•°æ®è¶…å‡ºåˆ—æ•°ï¼Œåªå–ä¸Žåˆ—æ•°åŒ¹é…çš„éƒ¨åˆ†
            data.append(values[:len(column_names)])
        elif len(values) > 0:  # å¿½ç•¥ç©ºè¡Œ
            # å¦‚æžœæ•°æ®ä¸è¶³ï¼Œå¡«å……ç©ºå€¼
            values_filled = values + [''] * (len(column_names) - len(values))
            data.append(values_filled)
    
    if not data:
        logging.warning(f"æ–‡ä»¶ä¸åŒ…å«æ•°æ®: {tab_file_path}")
        # åˆ›å»ºç©ºDataFrame
        df = pd.DataFrame(columns=column_names)
    else:
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(data, columns=column_names)
    
    # è½¬æ¢æ•°å€¼åˆ—
    for col in df.columns:
        try:
            df[col] = pd.to_numeric(df[col])
        except:
            pass  # å¦‚æžœè½¬æ¢å¤±è´¥ï¼Œä¿ç•™ä¸ºå­—ç¬¦ä¸²
    
    # ðŸ†• æŒ‰åŒ–å­¦ä½ç§»(X_PPM)é™åºæŽ’åº - Deep Pickerè¾“å‡ºæ˜¯æ— åºçš„ï¼Œéœ€è¦æŽ’åºä»¥ä¾¿åŽç»­åˆ†æž
    if 'X_PPM' in df.columns and len(df) > 0:
        # é™åºæŽ’åˆ—ï¼šä»Žé«˜ppmåˆ°ä½Žppmï¼ˆNMRè°±å›¾çš„æ ‡å‡†æ˜¾ç¤ºæ–¹å¼ï¼‰
        df = df.sort_values('X_PPM', ascending=False).reset_index(drop=True)
        ppm_max = df['X_PPM'].max()
        ppm_min = df['X_PPM'].min()
        logging.info(f"å·²æŒ‰X_PPMé™åºæŽ’åºï¼ŒppmèŒƒå›´: {ppm_max:.4f} - {ppm_min:.4f} ({len(df)} ä¸ªå³°)")
    
    # æ·»åŠ å…ƒæ•°æ®åˆ—
    df['strain_id'] = original_strain_id  # ä¿å­˜åŽŸå§‹èŒæ ªID
    df['simple_strain_id'] = strain_id    # ä¿å­˜ç®€åŒ–çš„èŒæ ªID
    df['sample_id'] = original_sample_id  # ä¿å­˜åŽŸå§‹æ ·æœ¬ID
    df['simple_sample_id'] = sample_id    # ä¿å­˜ç®€åŒ–çš„æ ·æœ¬ID
    df['source_file'] = str(tab_file_path)
    
    # Save as CSV
    df.to_csv(csv_file_path, index=False)
    
    logging.info(f"Converted tab file to CSV: {csv_file_path}")
    return str(csv_file_path)

def find_and_convert_tab_files(base_dir, output_base_dir=None, use_simple_names=True, in_place=True):
    """
    æŸ¥æ‰¾å¹¶è½¬æ¢æ‰€æœ‰tabæ–‡ä»¶ä¸ºCSVæ ¼å¼
    
    Parameters:
        base_dir (str): åŸºç¡€ç›®å½•ï¼Œç”¨äºŽæœç´¢tabæ–‡ä»¶
        output_base_dir (str): è¾“å‡ºCSVæ–‡ä»¶çš„åŸºç¡€ç›®å½•ï¼ˆå¦‚æžœä¸æ˜¯åŽŸåœ°è½¬æ¢ï¼‰
        use_simple_names (bool): æ˜¯å¦ä½¿ç”¨ç®€åŒ–çš„èŒæ ªå’Œæ ·æœ¬åç§°
        in_place (bool): æ˜¯å¦åœ¨åŽŸåœ°ä¿å­˜CSVæ–‡ä»¶ï¼ˆæ”¾å…¥ä¸Žtabæ–‡ä»¶ç›¸åŒçš„ç›®å½•ï¼‰
    
    Returns:
        list: åˆ›å»ºçš„æ‰€æœ‰CSVæ–‡ä»¶çš„è·¯å¾„
    """
    base_dir = Path(base_dir)
    created_files = []
    found_files = 0
    
    # å¦‚æžœæŒ‡å®šäº†è¾“å‡ºç›®å½•ä¸”ä¸æ˜¯åŽŸåœ°è½¬æ¢ï¼Œåˆ›å»ºè¾“å‡ºç›®å½•
    if output_base_dir is not None and not in_place:
        output_base_dir = Path(output_base_dir)
        output_base_dir.mkdir(parents=True, exist_ok=True)
    
    # æŸ¥æ‰¾æ‰€æœ‰tabæ–‡ä»¶
    logging.info(f"å¼€å§‹åœ¨{base_dir}ä¸­æŸ¥æ‰¾tabæ–‡ä»¶...")
    
    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.endswith('.tab'):
                found_files += 1
                tab_file = Path(root) / file
                
                # ç¡®å®šè¾“å‡ºç›®å½•
                if in_place:
                    # åŽŸåœ°ä¿å­˜CSV - ç›´æŽ¥æ”¾å…¥tabæ–‡ä»¶æ‰€åœ¨ç›®å½•
                    output_dir = tab_file.parent
                else:
                    # åœ¨æ–°ä½ç½®åˆ›å»ºCSVç›®å½•ç»“æž„
                    # é¢„æœŸçš„åŽŸå§‹è·¯å¾„: /ä¸»æ–‡ä»¶å¤¹/èŒæ ªåç§°/æ ·æœ¬å/10/nmrpipe/spectrum.tab
                    # ç›®æ ‡ç»“æž„: output_base_dir/èŒæ ªåç§°/csv/
                    
                    # å¯»æ‰¾èŒæ ªåå’Œæ ·æœ¬å
                    parts = list(tab_file.parts)
                    strain_id = None
                    sample_id = None
                    
                    # æŸ¥æ‰¾"nmrpipe"æ–‡ä»¶å¤¹ä½ç½®
                    nmrpipe_idx = -1
                    for i, part in enumerate(parts):
                        if part == "nmrpipe":
                            nmrpipe_idx = i
                            break
                    
                    if nmrpipe_idx > 2:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„è·¯å¾„æ·±åº¦
                        # nmrpipeçš„ä¸Šä¸¤çº§åº”è¯¥æ˜¯"10"æ–‡ä»¶å¤¹å’Œæ ·æœ¬å
                        if parts[nmrpipe_idx-1] == "10" and nmrpipe_idx >= 3:
                            strain_id = parts[nmrpipe_idx-3]
                    
                    if strain_id is None:
                        # ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                        rel_path = tab_file.relative_to(base_dir) if tab_file.is_relative_to(base_dir) else Path(tab_file.name)
                        parts = list(rel_path.parts)
                        if len(parts) > 0:
                            strain_id = parts[0]  # å‡è®¾ç¬¬ä¸€çº§ç›®å½•æ˜¯èŒæ ª
                        else:
                            strain_id = "unknown_strain"
                    
                    # åˆ›å»ºè¾“å‡ºç›®å½•
                    if use_simple_names:
                        strain_id = extract_simple_name(strain_id)
                    
                    output_dir = output_base_dir / strain_id / "csv"
                
                # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                output_dir.mkdir(parents=True, exist_ok=True)
                
                # è½¬æ¢tabæ–‡ä»¶
                try:
                    csv_file = tab_to_csv(
                        tab_file,
                        output_dir=output_dir,
                        use_simple_names=use_simple_names
                    )
                    created_files.append(csv_file)
                    logging.info(f"å·²è½¬æ¢: {tab_file} -> {csv_file}")
                except Exception as e:
                    logging.error(f"è½¬æ¢{tab_file}æ—¶å‡ºé”™: {str(e)}")
                    logging.exception("è¯¦ç»†é”™è¯¯:")
    
    logging.info(f"æ‰¾åˆ°{found_files}ä¸ªtabæ–‡ä»¶ï¼ŒæˆåŠŸè½¬æ¢{len(created_files)}ä¸ª")
    return created_files

def organize_nmr_samples(base_dir, output_dir=None):
    """
    Organize NMR samples by strain, ensuring each strain has its set of samples
    with standardized naming.
    
    Parameters:
        base_dir (str): Base directory with raw NMR data
        output_dir (str): Output directory for organized data
    
    Returns:
        dict: Dictionary mapping strains to their samples
    """
    base_dir = Path(base_dir)
    if output_dir is None:
        output_dir = base_dir / "organized"
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Identify NMR experiment types
    nmr_types = ['HSQC', 'COSY', 'TOCSY', 'NOESY', '1H', 'NMR', '13C']
    
    # Dictionary to track strain -> samples
    strain_samples = {}
    
    # Dictionary to track sample types
    sample_counts = {}
    
    # Walk through the directory structure
    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.endswith('.tab'):
                tab_file = Path(root) / file
                
                # Get relative path to determine structure
                try:
                    rel_path = tab_file.relative_to(base_dir)
                    path_parts = list(rel_path.parts)
                except ValueError:
                    # If not relative, use full path
                    path_parts = list(tab_file.parts)
                
                # Default assignments
                strain_id = None
                sample_type = None
                
                # Try to extract strain and sample type from path or filename
                if len(path_parts) >= 2:
                    # Assume first part is strain and extract experiment type
                    strain_id = path_parts[0]
                    
                    # Look for experiment type in directory names or file name
                    for part in path_parts[1:] + [file]:
                        for nmr_type in nmr_types:
                            if nmr_type in part:
                                sample_type = nmr_type
                                break
                        if sample_type:
                            break
                else:
                    # Try to extract from filename
                    for nmr_type in nmr_types:
                        if nmr_type in file:
                            sample_type = nmr_type
                            break
                
                # If we couldn't identify, use defaults
                if strain_id is None:
                    strain_id = "unknown_strain"
                    
                if sample_type is None:
                    # Use the parent directory name as sample type
                    sample_type = Path(root).name
                    if sample_type == base_dir.name:
                        sample_type = "unknown_type"
                
                # Create unique sample ID based on type and count
                if strain_id not in sample_counts:
                    sample_counts[strain_id] = {}
                
                if sample_type not in sample_counts[strain_id]:
                    sample_counts[strain_id][sample_type] = 0
                
                sample_counts[strain_id][sample_type] += 1
                count = sample_counts[strain_id][sample_type]
                
                sample_id = f"{sample_type}" if count == 1 else f"{sample_type}_{count}"
                
                # Track samples for this strain
                if strain_id not in strain_samples:
                    strain_samples[strain_id] = []
                
                if sample_id not in strain_samples[strain_id]:
                    strain_samples[strain_id].append(sample_id)
                
                # Create organized directory structure
                org_strain_dir = output_dir / strain_id
                org_sample_dir = org_strain_dir / sample_id
                org_sample_dir.mkdir(parents=True, exist_ok=True)
                
                # Copy and rename the tab file with standardized name
                dest_file = org_sample_dir / f"{strain_id}_{sample_id}.tab"
                shutil.copy2(tab_file, dest_file)
                
                # Convert to CSV
                csv_dir = org_sample_dir / "nmrpipe"
                try:
                    tab_to_csv(
                        str(dest_file),
                        output_dir=str(csv_dir),
                        strain_id=strain_id,
                        sample_id=sample_id
                    )
                except Exception as e:
                    logging.error(f"Error converting organized tab file {dest_file}: {str(e)}")
    
    return strain_samples

if __name__ == "__main__":
    # Setup basic logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # Test with a sample tab file
    import sys
    if len(sys.argv) > 1:
        tab_file = sys.argv[1]
        csv_file = tab_to_csv(tab_file)
        print(f"Converted {tab_file} to {csv_file}")
